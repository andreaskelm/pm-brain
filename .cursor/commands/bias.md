```
# Bias Task

Pre-decision cognitive bias check. Identify biases affecting your thinking and apply debiasing strategies before making important product decisions.

## Before You Begin

**Important:** Having biases is not a character flaw - it's how human brains work. The goal is awareness and systematic debiasing, not perfection.

Reference: @02-Methods-and-Tools/2.0-Foundations/2.0.2-Bias/1-bias-framework.md

## Decision Context

What decision are you making?
- Brief description:
- Why now?
- Who's affected?
- Reversible or one-way door?

## Quick Bias Checklist

Check for these top 10 PM biases:

### 1. Confirmation Bias ‚ö†Ô∏è CRITICAL

**What it is:** Seeking information that confirms existing beliefs, ignoring contradictory evidence

**Check:**
- [ ] Have I actively sought disconfirming evidence?
- [ ] Did I interview users who DON'T use/like the product?
- [ ] Am I asking open-ended, unbiased questions?
- [ ] Have I consulted people who disagree with my hypothesis?
- [ ] Can I name 3 pieces of evidence that contradict my belief?

**If present, do:**
- Pre-mortem: Assume this fails. Why?
- Actively seek disconfirming evidence
- Include skeptics in research/decisions
- Assign someone to argue the opposite

---

### 2. Anchoring Bias ‚ö†Ô∏è CRITICAL

**What it is:** Over-relying on first piece of information (numbers, estimates, prices)

**Check:**
- [ ] Where did this number come from?
- [ ] Did I generate my own estimate before hearing others'?
- [ ] Have I used historical data to calibrate?
- [ ] Did I build bottom-up from components?
- [ ] Can I justify this number independently of the anchor?

**If present, do:**
- Get 3+ independent estimates before discussing
- Use historical data from similar projects
- Build bottom-up estimation from components
- Explicitly question the first number shared

---

### 3. Sunk Cost Fallacy ‚ö†Ô∏è CRITICAL

**What it is:** Continuing investment because of past investment (time, money, effort)

**Check:**
- [ ] Would we start this project TODAY with current information?
- [ ] Am I defending this based on past investment?
- [ ] Have I calculated opportunity cost?
- [ ] Do we have clear kill criteria?
- [ ] What's the best use of our next dollar/hour?

**If present, do:**
- Zero-based thinking: "Would we start this today?"
- Define kill criteria before starting projects
- External perspective: "What would we advise a friend?"
- Opportunity cost framing: "What else could we do with these resources?"

---

### 4. Availability Heuristic üü° HIGH

**What it is:** Overweighting recent or memorable events

**Check:**
- [ ] Have I checked how common this actually is?
- [ ] Am I reacting to recency instead of frequency?
- [ ] Did I wait before making this decision?
- [ ] Have I gathered feedback from multiple sources?
- [ ] Does this align with strategic priorities?

**If present, do:**
- Check actual frequency in data (base rate analysis)
- Wait 24-48 hours before reacting to "urgent" issues
- Gather feedback from multiple channels, not just loudest
- Use prioritization framework (RICE/ICE), not recency

---

### 5. Optimism Bias üü° HIGH

**What it is:** Underestimating risks, timelines, costs; overestimating success

**Check:**
- [ ] Have I looked at how long similar projects took?
- [ ] Did I do a pre-mortem (assume failure, work backward)?
- [ ] Have I added appropriate buffers?
- [ ] What's my track record on similar estimates?
- [ ] What could go wrong that I haven't considered?

**If present, do:**
- Reference class forecasting (use historical data)
- Pre-mortem: Assume failure, identify causes
- Outside view: How long did similar projects take?
- Add buffers: Multiply estimates by 1.5-2x
- Track accuracy: Compare actuals vs. estimates over time

---

### 6. Bandwagon Effect / Groupthink üü° MEDIUM

**What it is:** Following others' opinions because "everyone's doing it"

**Check:**
- [ ] Does this fit OUR unique strategy?
- [ ] Have I heard dissenting opinions?
- [ ] Did we generate ideas independently first?
- [ ] Can I articulate why this is right for us (not just others)?
- [ ] What would make us unique if we DON'T do this?

**If present, do:**
- Strategic fit check: Does this align with OUR strategy?
- Assign devil's advocate role
- Silent brainstorming (write ideas before discussing)
- "5 Whys" technique: Why do we need this? (5x)
- Create safe channels for dissent

---

### 7. Halo Effect üü° MEDIUM

**What it is:** Assuming expertise in one area = expertise in all areas

**Check:**
- [ ] Is this person an expert in this SPECIFIC domain?
- [ ] Have we evaluated ideas blind to source?
- [ ] Did we get diverse expert input?
- [ ] Can they show evidence/data for their position?
- [ ] Are we deferring due to general reputation vs. specific expertise?

**If present, do:**
- Match expert to specific question domain
- Blind evaluation (evaluate ideas without knowing source)
- Get multiple expert perspectives
- Question credentials: "What makes them expert in THIS?"
- Ask for evidence/data, not just credentials

---

### 8. Authority Bias / HiPPO üü° MEDIUM

**What it is:** Overvaluing opinions of authority figures (Highest Paid Person's Opinion)

**Check:**
- [ ] Would we prioritize this if it weren't from [authority]?
- [ ] Have we evaluated using our prioritization framework?
- [ ] Did we present data before opinions?
- [ ] Is there space to respectfully disagree?
- [ ] What does the evidence say (independent of who suggested it)?

**If present, do:**
- Data-first culture: Present data before opinions
- Anonymous input: Collect ideas blind to seniority
- Disagree and commit: Norm of respectful disagreement
- Use decision framework (RICE/ICE) for all suggestions
- Leader modeling: Execs should ask "what does data say?"

---

### 9. Recency Bias üü¢ LOW-MEDIUM

**What it is:** Recent events seem more important than they are

**Check:**
- [ ] Have I looked at longer-term data (12+ months)?
- [ ] Is this a trend or an anomaly?
- [ ] Have we seen this pattern before? What happened?
- [ ] Are we reacting too quickly to recent events?
- [ ] What does the strategic roadmap say vs. latest fire?

**If present, do:**
- Look at 12+ months of data, not just last month
- Trend analysis: Is this anomaly or pattern?
- Cooling off period before reacting
- Pattern recognition: "Have we seen this before?"
- Monthly trends vs. daily fluctuations

---

### 10. Loss Aversion üü¢ LOW-MEDIUM

**What it is:** Fear of losses weighs more than equivalent gains

**Check:**
- [ ] Are we being overly risk-averse?
- [ ] Have we quantified the actual risk?
- [ ] What's the opportunity cost of inaction?
- [ ] Can we test this with a small experiment first?
- [ ] What would a new leader do without our history?

**If present, do:**
- Frame as gains (focus on what we gain, not lose)
- Quantify actual risk vs. reward
- Small experiments to test without full commitment
- Portfolio approach: Some bets should be risky
- Prospective thinking: "What would new PM/CEO do?"

---

## Product Sense Check

Beyond cognitive biases, check your product intuition:

### Gut Check Questions
- What does your product sense tell you?
- Does this feel right or wrong? Why?
- What would you tell a friend in this situation?
- What would make this obviously right in 12 months?
- What would make this obviously wrong?

### Assumptions Check
- [ ] What assumptions am I making?
- [ ] Which assumptions are testable?
- [ ] Which are highest risk if wrong?
- [ ] How can I validate them quickly?

Reference: @02-Methods-and-Tools/2.0-Foundations/2.0.1-Mental-Models/1-Decision-Making/3-assumptions-framework.md

## Output Format

### üéØ Decision Summary
**What:** [Decision being made]
**Why now:** [Timing/urgency]
**Reversibility:** [One-way door / Two-way door]

---

### ‚ö†Ô∏è Biases Detected

**HIGH RISK:**
- **[Bias name]:** [How it's affecting this decision]
  - Mitigation: [Specific action to take]

**MEDIUM RISK:**
- **[Bias name]:** [How it's affecting this decision]
  - Mitigation: [Specific action to take]

**LOW RISK:**
- **[Bias name]:** [How it's affecting this decision]

---

### ‚úÖ Debiasing Actions

**Before Deciding:**
1. [Action] - [By when]
2. [Action] - [By when]
3. [Action] - [By when]

**To Validate:**
- [Assumption 1] - [How to test]
- [Assumption 2] - [How to test]

**Dissenting Views to Seek:**
- [Who to consult]
- [What questions to ask]

---

### üß† Product Sense Check

**Gut feeling:** [What does intuition say]

**Key assumptions:**
- [Assumption 1] - Confidence: [High/Med/Low]
- [Assumption 2] - Confidence: [High/Med/Low]
- [Assumption 3] - Confidence: [High/Med/Low]

**What would make this obviously right:** [In 12 months]
**What would make this obviously wrong:** [In 12 months]

---

### üìã Decision Documentation

**Record this decision:**
- Where: @04-Initiatives/[INITIATIVE]/decisions.md
- Include: Date, decision, context, biases considered, mitigation, owner
- Review: [When to check if decision was good]

---

## After the Decision

### Track & Learn

Document in decision log:

```markdown
## [Date] - [Decision Title]

**Decision:** [What we decided]

**Context:** [Why this decision, what was happening]

**Options Considered:**
- Option A: [Pros/cons]
- Option B: [Pros/cons]
- Chosen: [Which and why]

**Biases Considered:**
- [Bias 1]: [How we mitigated]
- [Bias 2]: [How we mitigated]

**Assumptions:**
- [Assumption 1] - [How we'll validate]
- [Assumption 2] - [How we'll validate]

**Review Date:** [When to assess if this was right]

**Owner:** [DRI]

**Links:** [Supporting docs, data, research]
```

### Quarterly Bias Audit

Review major decisions quarterly:

```
Quarter: [Q1/Q2/Q3/Q4 20XX]

Major decisions: [Count]

Most common bias: [Bias name]
Least debiased decisions: [Examples]
Most effective debiasing: [Strategy]

Actions for next quarter:
1. [Specific improvement]
2. [Specific improvement]
```

Reference: @02-Methods-and-Tools/2.0-Foundations/2.0.2-Bias/1-bias-framework.md (full audit template)

---

## Integration with Other Commands

- **Before starting initiative:** Use /start (includes bias check)
- **Before major decisions:** Use this command
- **Weekly reflection:** Check for bias patterns in decisions
- **If stuck:** Use /unstuck (may route back to bias check)

## When to Use This Command

**Always use before:**
- Strategic decisions (direction, OKRs, roadmap)
- Resource allocation (hiring, budget, prioritization)
- Go/no-go decisions on initiatives
- Major feature decisions
- Pricing decisions
- Estimates and commitments

**Use frequently for:**
- Prioritization discussions
- Opportunity assessments
- Post-mortems (what biases affected us?)
- Team retrospectives

**Don't overthink for:**
- Easily reversible decisions (two-way doors)
- Low-impact decisions
- Already-validated assumptions

## Common Scenarios

**"We need to decide NOW"**
- Is it really urgent or availability heuristic?
- Can it wait 24 hours for proper bias check?
- If truly urgent: Do quick checklist (5 min)
- Document decision and biases for later review

**"Everyone on the team agrees"**
- RED FLAG: Potential groupthink or bandwagon
- Actively seek dissenting opinions
- Assign devil's advocate
- Ask: "What would make this wrong?"

**"This will definitely work"**
- RED FLAG: Optimism bias
- Do pre-mortem: Assume it fails, why?
- Check historical data for similar initiatives
- Add appropriate buffers/risk mitigation

**"We've already invested 6 months"**
- RED FLAG: Sunk cost fallacy
- Ask: "Would we start this TODAY?"
- Calculate opportunity cost
- Consider kill criteria

## References

- Full framework: @02-Methods-and-Tools/2.0-Foundations/2.0.2-Bias/1-bias-framework.md
- Decision-making models: @02-Methods-and-Tools/2.0-Foundations/2.0.1-Mental-Models/1-Decision-Making
- Pre-mortems: @02-Methods-and-Tools/2.0-Foundations/2.0.1-Mental-Models/1-Decision-Making/1-pre-mortems.md
- Assumptions framework: @02-Methods-and-Tools/2.0-Foundations/2.0.1-Mental-Models/1-Decision-Making/3-assumptions-framework.md
- Self-reflection: @02-Methods-and-Tools/2.0-Foundations/2.0.3-Self-Reflection
```
